{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "try:\n",
    "  import timm\n",
    "except:\n",
    "  print('timm does not exist')\n",
    "  !pip install timm\n",
    "  import timm\n",
    "\n",
    "try:\n",
    "  import torchmetrics\n",
    "except:\n",
    "  !pip install torchmetrics\n",
    "  import torchmetrics\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"preprocessed_data/train_df.pkl\", 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "    X_train = train_df.drop(columns=[\"label\"])\n",
    "    y_train = train_df[[\"label\"]]\n",
    "\n",
    "with open(\"preprocessed_data/test_df.pkl\", 'rb') as f:\n",
    "    test_df = pickle.load(f)\n",
    "    X_test = test_df.drop(columns=[\"label\"])\n",
    "    y_test = test_df[[\"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning using ResNet\n",
    "Reference: https://www.kaggle.com/code/paulojunqueira/mnist-with-pytorch-and-transfer-learning-timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X.values.reshape((-1,64,64,1))\n",
    "        self.y = y.values.reshape(-1,1)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, random_state=1, test_size=0.2)\n",
    "\n",
    "# Define dataset objects\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "ds_train = customDataset(X_tr, y_tr, transform=transform)\n",
    "ds_val = customDataset(X_val, y_val, transform=transform)\n",
    "ds_test = customDataset(X_test, y_test, transform=transform)\n",
    "\n",
    "# Create Dataset Loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(ds_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_model = timm.create_model(model_name=\"resnet50\", pretrained=True, num_classes=5, in_chans=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(timm_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optimizer, loss_fn, accuracy_fn, device):\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Push to device (cuda)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Feedforward\n",
    "        logits = model(X.float())\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, y.long().squeeze())\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        y_preds = logits.argmax(dim=1)\n",
    "        train_acc += accuracy_fn(y_preds, y.long().squeeze()).item()\n",
    "\n",
    "        all_preds += [y_preds]\n",
    "        all_targets += [y.long().squeeze()]\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {100* train_acc:.2f}%\")\n",
    "    return train_loss, train_acc, all_preds, all_targets\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, accuracy_fn, device):\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    all_preds, all_targets = [], []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X.float())\n",
    "            loss = loss_fn(logits, y.long().squeeze())\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            y_preds = logits.argmax(dim=1)\n",
    "            test_acc += accuracy_fn(y_preds, y.long().squeeze()).item()\n",
    "\n",
    "            all_preds += [y_preds]\n",
    "            all_targets += [y.long().squeeze()]\n",
    "\n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {100* test_acc:.2f}%\")\n",
    "\n",
    "    return test_loss, test_acc, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Current epoch: 1 --------------------------------------------------\n",
      "Train loss: 0.50197 | Train accuracy: 82.13%\n",
      "Test loss: 0.18933 | Test accuracy: 93.53%\n",
      "-------------------------------------------------- Current epoch: 2 --------------------------------------------------\n",
      "Train loss: 0.11140 | Train accuracy: 96.49%\n",
      "Test loss: 0.08591 | Test accuracy: 97.18%\n",
      "-------------------------------------------------- Current epoch: 3 --------------------------------------------------\n",
      "Train loss: 0.06890 | Train accuracy: 97.68%\n",
      "Test loss: 0.10113 | Test accuracy: 96.72%\n",
      "-------------------------------------------------- Current epoch: 4 --------------------------------------------------\n",
      "Train loss: 0.04565 | Train accuracy: 98.49%\n",
      "Test loss: 0.07197 | Test accuracy: 97.85%\n",
      "-------------------------------------------------- Current epoch: 5 --------------------------------------------------\n",
      "Train loss: 0.03630 | Train accuracy: 98.83%\n",
      "Test loss: 0.07501 | Test accuracy: 97.33%\n",
      "-------------------------------------------------- Current epoch: 6 --------------------------------------------------\n",
      "Train loss: 0.01759 | Train accuracy: 99.53%\n",
      "Test loss: 0.03808 | Test accuracy: 98.71%\n",
      "-------------------------------------------------- Current epoch: 7 --------------------------------------------------\n",
      "Train loss: 0.00655 | Train accuracy: 99.82%\n",
      "Test loss: 0.03655 | Test accuracy: 98.98%\n",
      "-------------------------------------------------- Current epoch: 8 --------------------------------------------------\n",
      "Train loss: 0.00655 | Train accuracy: 99.78%\n",
      "Test loss: 0.03450 | Test accuracy: 98.87%\n",
      "-------------------------------------------------- Current epoch: 9 --------------------------------------------------\n",
      "Train loss: 0.00380 | Train accuracy: 99.94%\n",
      "Test loss: 0.03528 | Test accuracy: 99.03%\n",
      "-------------------------------------------------- Current epoch: 10 --------------------------------------------------\n",
      "Train loss: 0.00321 | Train accuracy: 99.92%\n",
      "Test loss: 0.03312 | Test accuracy: 99.02%\n",
      "-------------------------------------------------- Current epoch: 11 --------------------------------------------------\n",
      "Train loss: 0.00356 | Train accuracy: 99.88%\n",
      "Test loss: 0.03610 | Test accuracy: 98.92%\n",
      "-------------------------------------------------- Current epoch: 12 --------------------------------------------------\n",
      "Train loss: 0.00391 | Train accuracy: 99.90%\n",
      "Test loss: 0.03263 | Test accuracy: 99.03%\n",
      "-------------------------------------------------- Current epoch: 13 --------------------------------------------------\n",
      "Train loss: 0.00242 | Train accuracy: 99.97%\n",
      "Test loss: 0.03288 | Test accuracy: 98.87%\n",
      "-------------------------------------------------- Current epoch: 14 --------------------------------------------------\n",
      "Train loss: 0.00217 | Train accuracy: 99.95%\n",
      "Test loss: 0.03509 | Test accuracy: 98.87%\n",
      "-------------------------------------------------- Current epoch: 15 --------------------------------------------------\n",
      "Train loss: 0.00299 | Train accuracy: 99.92%\n",
      "Test loss: 0.03412 | Test accuracy: 98.97%\n",
      "-------------------------------------------------- Current epoch: 16 --------------------------------------------------\n",
      "Train loss: 0.00227 | Train accuracy: 99.95%\n",
      "Test loss: 0.03540 | Test accuracy: 98.97%\n",
      "-------------------------------------------------- Current epoch: 17 --------------------------------------------------\n",
      "Train loss: 0.00201 | Train accuracy: 99.96%\n",
      "Test loss: 0.03377 | Test accuracy: 98.98%\n",
      "Early Stopping Triggered\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "best_val_loss = float(\"inf\")\n",
    "early_stopping_counter = 0\n",
    "early_stopping_threshold = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"-\"*50 + f\" Current epoch: {epoch + 1} \" + \"-\"*50)\n",
    "    train_loss, train_acc, train_preds, train_targets = train_step(\n",
    "        model=timm_model,\n",
    "        dataloader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_preds, val_targets = test_step(\n",
    "        model=timm_model,\n",
    "        dataloader=val_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(timm_model.state_dict(), \"models/resnet_best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_threshold:\n",
    "            print(\"Early Stopping Triggered\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results using Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30520 | Test accuracy: 92.19%\n"
     ]
    }
   ],
   "source": [
    "model_path = \"models/resnet_best_model.pth\"\n",
    "timm_model = timm.create_model(model_name=\"resnet50\", num_classes=5, in_chans=1)\n",
    "timm_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.Adam(timm_model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy_fn = torchmetrics.Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "test_loss, test_acc, test_preds, test_targets = test_step(\n",
    "        model=timm_model,\n",
    "        dataloader=test_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7500    0.8571        60\n",
      "           1     0.8551    0.9833    0.9147        60\n",
      "           2     0.8293    0.9714    0.8947        35\n",
      "           3     0.9677    1.0000    0.9836        60\n",
      "           4     0.9643    0.9000    0.9310        30\n",
      "\n",
      "    accuracy                         0.9184       245\n",
      "   macro avg     0.9233    0.9210    0.9162       245\n",
      "weighted avg     0.9278    0.9184    0.9166       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds_list = [pred.item() for batch_preds in test_preds for pred in batch_preds]\n",
    "test_targets_list = [target.item() for batch_targets in test_targets for target in batch_targets]\n",
    "\n",
    "report = classification_report(test_targets_list, test_preds_list, digits=4)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
